{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f46561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
    "from langchain.messages import HumanMessage,SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d632f45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16db269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt):\n",
    "\n",
    "    llm = ChatGroq(model=\"openai/gpt-oss-20b\")\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b6f03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wind is a restless storyteller, tugging at the edges of the world with a breath that carries secrets from distant horizons. It whispers through the leaves, turning them into a rustling choir, and carries the scent of distant seas, the salt of a storm that has yet to break. In its cool sigh, there is a promise of change, a hint that even the most stubborn roots will bend to the rhythm of the unseen. And as it dances across the open plain, it leaves behind a trail of shimmering dust, reminding us that even the quietest moments can stir the heart of the earth.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The wind is \"\n",
    "response = llm_model(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02ed807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The future of artificial intelligence is a tapestry woven from both promise and caution, where advances in capability are matched by an increasing need for thoughtful governance and ethical stewardship.**\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Ubiquitous, Contextâ€‘Aware Assistance**\n",
      "\n",
      "- **Seamless Humanâ€“AI Collaboration**: Everyday devicesâ€”from smart homes to wearablesâ€”will embed AI that anticipates needs, adapts to user preferences, and operates in realâ€‘time. Think of a â€œdigital companionâ€ that can draft emails, schedule meetings, and even suggest creative ideas based on your mood and context.\n",
      "- **Personalized Education & Training**: AI tutors will adapt curricula to individual learning styles, pacing, and interests, making highâ€‘quality education more accessible globally.\n",
      "\n",
      "### 2. **Advances in Explainability and Trust**\n",
      "\n",
      "- **Transparent Models**: As AI systems become more complex, the push for explainable AI (XAI) will drive research into interpretable architectures and postâ€‘hoc explanation tools that help users understand decisions.\n",
      "- **Humanâ€‘inâ€‘theâ€‘Loop**: Critical domains (healthcare, finance, autonomous vehicles) will adopt hybrid models where humans supervise or override AI outputs, ensuring safety and accountability.\n",
      "\n",
      "### 3. **Ethics, Bias, and Fairness**\n",
      "\n",
      "- **Bias Auditing Frameworks**: Standardized audits and regulatory frameworks will be developed to detect and mitigate bias in training data and model behavior.\n",
      "- **Inclusive Design**: AI developers will be required to engage diverse stakeholder groups during design to prevent systemic exclusion and ensure that benefits are equitably distributed.\n",
      "\n",
      "### 4. **Regulation and Governance**\n",
      "\n",
      "- **Global AI Governance Bodies**: International coalitions (e.g., UN, OECD) will draft norms and treaties that govern the deployment of powerful AI, especially in military, surveillance, and critical infrastructure contexts.\n",
      "- **Dynamic Licensing Models**: Similar to software licenses, AI models may be subject to â€œAIâ€‘software licensesâ€ that specify permissible use cases, data handling, and safety standards.\n",
      "\n",
      "### 5. **Artificial General Intelligence (AGI) and Beyond**\n",
      "\n",
      "- **Incremental Pathways**: While true AGI remains speculative, incremental stepsâ€”such as more robust multiâ€‘modal learning, selfâ€‘supervised learning at scale, and better reasoning modulesâ€”will push the boundary of what machines can do.\n",
      "- **Safetyâ€‘First AGI Research**: Parallel research tracks will focus on value alignment, robustness, and controllability to ensure that any future AGI is beneficial and aligned with human values.\n",
      "\n",
      "### 6. **Economic and Societal Impact**\n",
      "\n",
      "- **Job Transformation**: Automation will displace routine tasks but also create new roles in AI maintenance, ethics oversight, and creative collaboration. Workforce retraining programs will become essential.\n",
      "- **Healthcare Revolution**: AI-driven diagnostics, personalized treatment plans, and drug discovery pipelines will shorten development times and improve patient outcomes.\n",
      "- **Environmental Monitoring**: AI will power largeâ€‘scale climate models, optimize energy grids, and monitor biodiversity, aiding in sustainable development goals.\n",
      "\n",
      "### 7. **Humanâ€‘Centric AI Design**\n",
      "\n",
      "- **Emotionally Intelligent Interfaces**: AI systems will recognize and respond to human emotions, leading to more natural interactions in customer service, therapy, and education.\n",
      "- **Privacyâ€‘Preserving AI**: Techniques like federated learning, differential privacy, and secure multiparty computation will allow AI to learn from distributed data without compromising individual privacy.\n",
      "\n",
      "### 8. **Emerging Technical Frontiers**\n",
      "\n",
      "- **Neuroâ€‘Inspired Computing**: Brainâ€‘computer interfaces and neuromorphic chips will enable more efficient, lowâ€‘power AI systems that mimic human cognition.\n",
      "- **Quantumâ€‘Enhanced AI**: Quantum algorithms may accelerate certain AI tasks (e.g., optimization, sampling) and open new algorithmic paradigms.\n",
      "\n",
      "---\n",
      "\n",
      "## Bottom Line\n",
      "\n",
      "The future of AI is not a single trajectory but a mosaic of intertwined developments. Technological progress will bring unprecedented benefitsâ€”improved health, smarter cities, deeper scientific insightsâ€”but it will also amplify existing societal challenges. Success will hinge on **collaborative governance**, **ethical foresight**, and a commitment to **humanâ€‘centered design**. If we steer the conversation toward inclusive, transparent, and responsible innovation, AI can become a powerful ally that uplifts humanity rather than a force that divides it.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The future of artificial intelligence is \"\n",
    "response = llm_model(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8757b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The benefits of using sustainable energy include:**\n",
      "\n",
      "| Category | Benefit | Why It Matters |\n",
      "|----------|---------|----------------|\n",
      "| **Environmental** | â€¢ **Reduced greenhouseâ€‘gas emissions** | Cuts carbon dioxide, methane, and other pollutants that drive climate change. |\n",
      "| | â€¢ **Lower air and water pollution** | Less smog, acid rain, and contaminated waterways, improving ecosystems and human health. |\n",
      "| | â€¢ **Conservation of natural resources** | Renewable sources (sun, wind, water, biomass) donâ€™t deplete finite fossilâ€‘fuel reserves. |\n",
      "| | â€¢ **Biodiversity protection** | Fewer largeâ€‘scale extraction sites (oil rigs, coal mines) mean less habitat loss. |\n",
      "| **Economic** | â€¢ **Job creation** | Renewableâ€‘energy sectors generate more jobs per unit of energy than fossil fuels, often in local communities. |\n",
      "| | â€¢ **Energy price stability** | Solar and wind costs have fallen dramatically; theyâ€™re less subject to geopolitical price shocks. |\n",
      "| | â€¢ **Stimulates innovation** | Drives advances in storage, grid management, and energy efficiency technologies. |\n",
      "| | â€¢ **Reduces dependence on imports** | Many countries can generate most of their power domestically, improving trade balances. |\n",
      "| **Social** | â€¢ **Improved public health** | Fewer respiratory and cardiovascular illnesses linked to cleaner air. |\n",
      "| | â€¢ **Energy access** | Solar, wind, and miniâ€‘grids can bring electricity to offâ€‘grid or remote areas. |\n",
      "| | â€¢ **Resilience and security** | Distributed renewable systems reduce vulnerability to single points of failure. |\n",
      "| | â€¢ **Community empowerment** | Communityâ€‘owned renewable projects can keep profits local and involve residents in decisionâ€‘making. |\n",
      "| **Technological** | â€¢ **Grid modernization** | Integration of renewables spurs smartâ€‘grid upgrades, demandâ€‘response, and energyâ€‘storage solutions. |\n",
      "| | â€¢ **Synergies with other sectors** | Electrification of transport, heating, and industry can pair seamlessly with renewables. |\n",
      "| **Longâ€‘term Sustainability** | â€¢ **Intergenerational equity** | Preserves a livable planet for future generations by limiting climateâ€‘related risks. |\n",
      "| | â€¢ **Circular economy potential** | Many renewable technologies (e.g., batteries) can be recycled, reducing waste. |\n",
      "\n",
      "**Bottom line:** Sustainable energy not only mitigates climate change but also delivers tangible economic, health, and societal benefitsâ€”making it a cornerstone of a resilient, inclusive, and prosperous future.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The benefits of using sustainable energy include \"\n",
    "response = llm_model(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8197bb",
   "metadata": {},
   "source": [
    "### Zeroshot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "575f04fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the following statement as true or false:\n",
    "            'The Eiffel Tower is located in Berlin.' \n",
    "            Answer: \n",
    "            \"\"\"\n",
    "\n",
    "response = llm_model(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0ce7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_type: movie_review\n",
      "response: Positive\n",
      "\n",
      "prompt_type: climate_change\n",
      "response: Climate change, driven mainly by fossilâ€‘fuel combustion, deforestation, and industrial activity since the 1800s, is causing longâ€‘term temperature and weather pattern shifts. Rising greenhouse gas levelsâ€”especially COâ‚‚ and methaneâ€”heat the planet, leading to melting glaciers and higher sea levels. These changes trigger more frequent, intense extreme weather events, threatening ecosystems and human health.\n",
      "\n",
      "prompt_type: translation\n",
      "response: èœ˜è››ä¾ æ˜¯ç¾å›½æ¼«ç”»å…¬å¸æ¼«å¨ï¼ˆMarvel Comicsï¼‰å‡ºç‰ˆçš„è¶…çº§è‹±é›„ã€‚ç”±ç¼–å‰§å…¼ç¼–è¾‘æ–¯å¦Â·æï¼ˆStan Leeï¼‰å’Œè‰ºæœ¯å®¶å²è’‚å¤«Â·è¿ªç‰¹ç§‘ï¼ˆSteve Ditkoï¼‰å…±åŒåˆ›ä½œï¼Œä»–é¦–æ¬¡å‡ºç°åœ¨ã€ŠæƒŠå¥‡å¹»æƒ³ã€‹ï¼ˆAmazing Fantasyï¼‰ç¬¬15æœŸï¼ˆ1962å¹´8æœˆï¼‰ï¼Œé‚£æ˜¯æ¼«ç”»é»„é‡‘æ—¶ä»£ï¼ˆSilver Age of Comic Booksï¼‰çš„ä¸€ä¸ªé‡Œç¨‹ç¢‘ã€‚èœ˜è››ä¾ è¢«è®¤ä¸ºæ˜¯æœ€å—æ¬¢è¿ã€å•†ä¸šä¸Šæœ€æˆåŠŸçš„è¶…çº§è‹±é›„ä¹‹ä¸€ï¼Œä»–çš„å½¢è±¡å·²åœ¨æ¼«ç”»ä¹¦ã€ç”µè§†èŠ‚ç›®ã€ç”µå½±ã€è§†é¢‘æ¸¸æˆã€å°è¯´å’Œæˆå‰§ç­‰å¤šç§åª’ä»‹ä¸­å¾—åˆ°å¹¿æ³›å‘ˆç°ã€‚\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'movie_review': 'Positive',\n",
       " 'climate_change': 'Climate change, driven mainly by fossilâ€‘fuel combustion, deforestation, and industrial activity since the 1800s, is causing longâ€‘term temperature and weather pattern shifts. Rising greenhouse gas levelsâ€”especially COâ‚‚ and methaneâ€”heat the planet, leading to melting glaciers and higher sea levels. These changes trigger more frequent, intense extreme weather events, threatening ecosystems and human health.',\n",
       " 'translation': 'èœ˜è››ä¾ æ˜¯ç¾å›½æ¼«ç”»å…¬å¸æ¼«å¨ï¼ˆMarvel Comicsï¼‰å‡ºç‰ˆçš„è¶…çº§è‹±é›„ã€‚ç”±ç¼–å‰§å…¼ç¼–è¾‘æ–¯å¦Â·æï¼ˆStan Leeï¼‰å’Œè‰ºæœ¯å®¶å²è’‚å¤«Â·è¿ªç‰¹ç§‘ï¼ˆSteve Ditkoï¼‰å…±åŒåˆ›ä½œï¼Œä»–é¦–æ¬¡å‡ºç°åœ¨ã€ŠæƒŠå¥‡å¹»æƒ³ã€‹ï¼ˆAmazing Fantasyï¼‰ç¬¬15æœŸï¼ˆ1962å¹´8æœˆï¼‰ï¼Œé‚£æ˜¯æ¼«ç”»é»„é‡‘æ—¶ä»£ï¼ˆSilver Age of Comic Booksï¼‰çš„ä¸€ä¸ªé‡Œç¨‹ç¢‘ã€‚èœ˜è››ä¾ è¢«è®¤ä¸ºæ˜¯æœ€å—æ¬¢è¿ã€å•†ä¸šä¸Šæœ€æˆåŠŸçš„è¶…çº§è‹±é›„ä¹‹ä¸€ï¼Œä»–çš„å½¢è±¡å·²åœ¨æ¼«ç”»ä¹¦ã€ç”µè§†èŠ‚ç›®ã€ç”µå½±ã€è§†é¢‘æ¸¸æˆã€å°è¯´å’Œæˆå‰§ç­‰å¤šç§åª’ä»‹ä¸­å¾—åˆ°å¹¿æ³›å‘ˆç°ã€‚'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_review_prompt = \"\"\"Classify the following movie review as positive or negative\n",
    "                        \"The Spiderman Movies are always entertaining and enjoyable for the audience, filled great action scenes and fight sequences.\"\n",
    "\n",
    "                        Answer:\n",
    "                        \"\"\"\n",
    "\n",
    "climate_change_prompt = \"\"\"\n",
    "                        Summarize the article within 2-3 lines. \n",
    "                        Climate change refers to long-term shifts in temperatures and weather patterns, primarily driven by human activities like burning fossil fuels, deforestation, and industrial processes since the 1800s. These actions release heat-trapping greenhouse gasesâ€”such as carbon dioxide and methaneâ€”increasing global temperatures. Consequences include melting glaciers, rising sea levels, and more frequent, severe extreme weather events like floods and droughts, which endanger ecosystems and human health.\n",
    "                        \"\"\"\n",
    "\n",
    "\n",
    "translation_prompt = \"\"\"\n",
    "Translate the following article from english to mandarin.\n",
    "\n",
    "Spider-Man is a superhero in American comic books published by Marvel Comics. Created by writer-editor Stan Lee and artist Steve Ditko, he first appeared in the anthology comic book Amazing Fantasy #15 (August 1962) in the Silver Age of Comic Books. Considered one of the most popular and commercially successful superheroes, he has been featured in comic books, television shows, films, video games, novels, and plays.\n",
    "\"\"\"\n",
    "\n",
    "responses = {}\n",
    "\n",
    "responses[\"movie_review\"] = llm_model(movie_review_prompt)\n",
    "responses[\"climate_change\"] = llm_model(climate_change_prompt)\n",
    "responses['translation']  = llm_model(translation_prompt)\n",
    "\n",
    "for prompt_type,response in responses.items():\n",
    "    print(f\"prompt_type: {prompt_type}\\nresponse: {response}\\n\")\n",
    "\n",
    "responses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86212ba8",
   "metadata": {},
   "source": [
    "### One shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761eba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:Here is an example of translating a sentence from English to French:\n",
      "\n",
      "            English: \"How is the weather today?\"\n",
      "            French: \"Comment est le temps aujourd'hui?\"\n",
      "\n",
      "            Now translate the following sentence from English to French:\n",
      "\n",
      "            English: \"Where is the nearest Supermarket?\"\n",
      "\n",
      "response:French: \"OÃ¹ est le supermarchÃ© le plus proche?\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "prompt = \"\"\"Here is an example of translating a sentence from English to French:\n",
    "\n",
    "            English: \"How is the weather today?\"\n",
    "            French: \"Comment est le temps aujourd'hui?\"\n",
    "\n",
    "            Now translate the following sentence from English to French:\n",
    "\n",
    "            English: \"Where is the nearest Supermarket?\"\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\",\n",
    "               temperature=0.1)\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f\"prompt:{prompt}\")\n",
    "print(f\"response:{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ffc3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Subject:** Updated Instructions for the Upcoming Final Examination â€“ Course CSâ€¯301\n",
      "\n",
      "Dear Dr.â€¯M.â€¯L.â€¯Harrison,\n",
      "\n",
      "I am writing to inform you of several important updates regarding the final examination for CSâ€¯301, scheduled for 12â€¯March 2026. These changes have been approved by the Academic Affairs Office and are intended to ensure a smooth and fair assessment process for all students.\n",
      "\n",
      "1. **Exam Date & Time**  \n",
      "   The exam will now commence at **09:00â€¯AM** and conclude at **12:00â€¯PM**. Please update the timetable accordingly.\n",
      "\n",
      "2. **Exam Venue**  \n",
      "   The examination will be held in **Roomâ€¯Bâ€‘204** (Engineering Building, 2nd floor). The room has been equipped with the necessary audioâ€‘visual aids and a backup power supply.\n",
      "\n",
      "3. **Exam Format**  \n",
      "   - **Sectionâ€¯A (Multipleâ€‘Choice):** 30 questions, 1â€¯point each.  \n",
      "   - **Sectionâ€¯B (Shortâ€‘Answer):** 5 questions, 5â€¯points each.  \n",
      "   - **Sectionâ€¯C (Programming Task):** 1 problem, 20â€¯points.  \n",
      "   All sections will be closedâ€‘book; students may bring a single, nonâ€‘electronic reference sheet.\n",
      "\n",
      "4. **Materials Allowed**  \n",
      "   Students may bring a **single laminated cheat sheet** (maximum 5â€¯cmâ€¯Ã—â€¯10â€¯cm) and a **calculator** (nonâ€‘graphing). No electronic devices are permitted.\n",
      "\n",
      "5. **Exam Proctoring**  \n",
      "   Two proctors will be present in the room. Students must check in at the entrance and present a valid student ID. Late arrivals will not be admitted.\n",
      "\n",
      "6. **Special Accommodations**  \n",
      "   Students who have previously requested accommodations must notify the Examination Office by 5â€¯PM on 10â€¯March. The office will coordinate with the exam room to provide the necessary arrangements.\n",
      "\n",
      "7. **Postâ€‘Exam Procedures**  \n",
      "   - Papers will be collected by 12:15â€¯PM and stored in the Examination Office.  \n",
      "   - Grading will commence immediately, with results posted to the LMS by 20â€¯March 2026.\n",
      "\n",
      "Please circulate this information to all enrolled students and update the course syllabus accordingly. If you have any questions or require further clarification, do not hesitate to contact me directly.\n",
      "\n",
      "Thank you for your cooperation and support in ensuring a fair and orderly examination process.\n",
      "\n",
      "Yours sincerely,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Title]  \n",
      "Department of Computer Science  \n",
      "University ofâ€¯X  \n",
      "Phone: +1â€¯555â€‘123â€‘4567  \n",
      "Email: your.email@university.edu\n"
     ]
    }
   ],
   "source": [
    "formal_email_prompt = \"\"\"\n",
    "\n",
    "Here is an example of a formal email:\n",
    "\n",
    "Subject: Delivery delay\n",
    "\n",
    " \n",
    "\n",
    "Dear Mr Pascal, \n",
    "\n",
    " \n",
    "\n",
    "We regret to inform you that we will not be able to respect the deadline previously agreed for the delivery of your order. Our supplier has warned us today that they are experiencing supply problems, which will result in a delay in our production chain. We count on your understanding and thank you for your patience. \n",
    "\n",
    " \n",
    "\n",
    "Please accept our apologies.\n",
    "\n",
    " \n",
    "\n",
    "Best regards,\n",
    "\n",
    "Now write a formal email to the course coordinator from university to provide updated instructions about the upcoming exam.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\",\n",
    "               temperature=0.1)\n",
    "response = llm.invoke(formal_email_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80cda7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain, software framework, large language models, llms, integration, applications\n"
     ]
    }
   ],
   "source": [
    "keyword_extraction_prompt = \"\"\"\n",
    "\n",
    "You are an expert NLP keyword extraction system. \n",
    "\n",
    "Task:\n",
    "Extract the most important words from the sentence \n",
    "\n",
    "Rules:;\n",
    "- Return 5-10 keywords \n",
    "- Use lowercase \n",
    "- No duplicates\n",
    "- No explanations \n",
    "- Output as comma-seperated list\n",
    "\n",
    "Example:\n",
    "Sentence: \"LangChain enables developers to build powerful AI agents with Groq models.\"\n",
    "Keywords: langchain, ai agents, groq models, developers, ai frameworks\n",
    "\n",
    "Now extract the keywords from:\n",
    "Sentence: \"LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications.\"\n",
    "Keywords: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\",\n",
    "               temperature=0.1)\n",
    "response = llm.invoke(keyword_extraction_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3dec4",
   "metadata": {},
   "source": [
    "### Few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4919d987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: Fear\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Here are few examples of  classifying emotions in statements:\n",
    "    Statement: 'I just won my first marathon'\n",
    "    Emotion: Joy \n",
    "\n",
    "    Statement:'I can't believe I lost my keys again'\n",
    "    Emotion: Frustration\n",
    "\n",
    "    Statement: 'My best friend is moving to another country'\n",
    "    Emotion: Sadness\n",
    "\n",
    "    Now, classify the emotion in the following satement:\n",
    "    Statement: 'That mvoie was so scary I had to cover my eyes'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f62a7",
   "metadata": {},
   "source": [
    "### Chain of Thought (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1565c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Stepâ€‘byâ€‘step calculation**\n",
      "\n",
      "| Step | Action | Numbers | Result |\n",
      "|------|--------|---------|--------|\n",
      "| 1 | **Start with the initial stock** | 22 apples | 22 apples |\n",
      "| 2 | **Subtract the apples sold today** | 22 â€“ 15 | 7 apples remain |\n",
      "| 3 | **Add the new delivery** | 7 + 8 | 15 apples in total |\n",
      "\n",
      "**Explanation**\n",
      "\n",
      "1. **Initial inventory** â€“ The store began the day with **22 apples**.\n",
      "2. **Sales** â€“ The store sold **15 apples**. Subtracting the sold apples from the initial inventory gives:\n",
      "   \\[\n",
      "   22 \\text{ apples} - 15 \\text{ apples} = 7 \\text{ apples}\n",
      "   \\]\n",
      "   So after the sales, **7 apples** are left in the store.\n",
      "3. **New delivery** â€“ The store receives a new shipment of **8 apples**. Adding these to the remaining apples gives:\n",
      "   \\[\n",
      "   7 \\text{ apples} + 8 \\text{ apples} = 15 \\text{ apples}\n",
      "   \\]\n",
      "   Thus, after the delivery, the store has **15 apples**.\n",
      "\n",
      "**Final answer:** There are **15 apples** in the store now.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Consider the problem: ''A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. \n",
    "            How many apples are there now?â€™'\n",
    "            \n",
    "            Break down each step of the calculation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161cf61",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Create CoT prompts for these scenarios:\n",
    "1. Write a prompt that asks the model to think through whether a student should study tonight or go to a movie with friends, considering their upcoming test in two days.\n",
    "2. Write a prompt that instructs the model to explain the step-by-step process of making a peanut butter and jelly sandwich.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d65395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Step 1 â€“ Evaluate the urgency of the test**  \n",
      "The test is in two days, which means you have a very short window to consolidate knowledge and address any weak spots. Exams of this nature usually carry a significant weight on your final grade, especially if itâ€™s a core course or a capstone. Missing or underperforming on it could jeopardize your GPA and your standing in the program.\n",
      "\n",
      "**Step 2 â€“ Consider your current preparation level**  \n",
      "Ask yourself:  \n",
      "- Have you covered all the material?  \n",
      "- Do you have a study plan or a list of topics you still need to review?  \n",
      "- Have you practiced past papers or sample questions?  \n",
      "If youâ€™re already on trackâ€”having completed most of the syllabus, done practice tests, and identified only a few gapsâ€”then youâ€™re in a good position to finish strong. If youâ€™re still missing key concepts or havenâ€™t practiced enough, youâ€™ll need more focused study time.\n",
      "\n",
      "**Step 3 â€“ Compare shortâ€‘term fun vs. longâ€‘term goals**  \n",
      "A movie tonight offers immediate enjoyment and a chance to unwind with friends. However, the longâ€‘term payoff of a high test score is far greater: it protects your GPA, keeps you on track for scholarships, honors, or future opportunities. The movie can be postponed to a later date when youâ€™re less pressured, or you could watch it after youâ€™ve completed a solid study session.\n",
      "\n",
      "**Step 4 â€“ Suggest the best decision**  \n",
      "If youâ€™re already wellâ€‘prepared, a brief, focused study block (e.g., 2â€“3 hours) followed by a short break to watch the movie would balance both needs. If youâ€™re still catching up, prioritize study first: set a timer for a 90â€‘minute â€œstudy sprint,â€ then reward yourself with the movie as a break. In either case, keep the study session structured and avoid distractions.\n",
      "\n",
      "---\n",
      "\n",
      "**Recommendation**  \n",
      "Given the test is only two days away and likely carries substantial weight, prioritize a focused study session first. Use a short, timed block to review the most critical material, then reward yourself with the movie as a break. This approach ensures you meet your academic responsibilities while still enjoying a wellâ€‘earned night out.\n"
     ]
    }
   ],
   "source": [
    "decision_making_prompt = \"\"\"You are a university senior who has good gpa and mentors juniors.You will help a student make good decisions.\n",
    "\n",
    "A student has an important test in 2 days. His friends invited him to a movie tonight. \n",
    "\n",
    "Let's think step by step. \n",
    "1. Evaluate the urgency of the test\n",
    "2. Consider the current preparation level \n",
    "3. Compare the short term fun and long term goals\n",
    "4. Suggest the best decision\n",
    "\n",
    "Finally give a recommendation in a short paragraph.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(decision_making_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a7c4447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Peanutâ€‘Butter & Jelly Sandwich â€“ Stepâ€‘byâ€‘Step**\n",
      "\n",
      "| # | Step | What to Do | Tips & Variations |\n",
      "|---|------|------------|-------------------|\n",
      "| 1 | **Gather Ingredients** | â€¢ 2 slices of bread (white, wholeâ€‘wheat, or your favorite)  <br>â€¢ 2â€“3 tbsp peanut butter (smooth or crunchy)  <br>â€¢ 2â€“3 tbsp jelly or jam (grape, strawberry, raspberry, etc.)  <br>â€¢ Optional: butter or margarine, honey, banana slices, or a pinch of salt | Use a highâ€‘quality peanut butter for richer flavor. |\n",
      "| 2 | **Prepare the Workspace** | Clean a flat surface or use a cutting board. Have a butter knife or spreader ready. | Keep the knife clean to avoid crossâ€‘contamination if youâ€™re using a separate knife for peanut butter and jelly. |\n",
      "| 3 | **Spread Peanut Butter** | 1. Place one slice of bread on the surface.  <br>2. Spread peanut butter evenly across the entire slice, reaching the edges. | For a lighter sandwich, use less peanut butter or a thin layer. |\n",
      "| 4 | **Spread Jelly** | 1. Place the second slice of bread on the surface.  <br>2. Spread jelly evenly over the entire slice, again reaching the edges. | If you like a sweeter sandwich, add a drizzle of honey on top of the jelly. |\n",
      "| 5 | **Combine the Slices** | Gently press the peanutâ€‘butterâ€‘side of the first slice onto the jellyâ€‘side of the second slice. | Press lightly to keep the sandwich together but avoid crushing the bread. |\n",
      "| 6 | **Optional Enhancements** | â€¢ Butter the outer sides of the sandwich and toast it in a skillet or sandwich press.  <br>â€¢ Add sliced banana, a sprinkle of cinnamon, or a pinch of sea salt for extra flavor. | Toasting adds crunch and warmth; just watch the butter so it doesnâ€™t burn. |\n",
      "| 7 | **Cut & Serve** | 1. Use a sharp knife to cut the sandwich in half (diagonal or straight).  <br>2. Serve immediately or wrap for later. | Cutting diagonally gives a larger surface area for each bite. |\n",
      "| 8 | **Clean Up** | Wash the knife, spreader, and any utensils used. | A quick rinse after each spread prevents sticky residue. |\n",
      "\n",
      "**Quick Checklist**\n",
      "\n",
      "- [ ] Bread ready  \n",
      "- [ ] Peanut butter spread  \n",
      "- [ ] Jelly spread  \n",
      "- [ ] Sandwich assembled  \n",
      "- [ ] Optional toast or extras added  \n",
      "- [ ] Cut and serve  \n",
      "\n",
      "Enjoy your classic peanutâ€‘butter & jelly sandwich!\n"
     ]
    }
   ],
   "source": [
    "pbj_prompt = \"\"\"You are a cook.\n",
    "                How can I prepare a peanut butter and jelly sandwich. \n",
    "\n",
    "                Can you break it down step by step.\"\"\"\n",
    "\n",
    "response = llm.invoke(pbj_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9dad3c",
   "metadata": {},
   "source": [
    "### Self-consistency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e404d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
      "\n",
      "            Provide three independent calculations and explanations, then determine the most consistent result.\n",
      "\n",
      "\n",
      "\n",
      "response : content='**Problem recap**\\n\\n- When you were 6\\u202fyears old, your sister was *half* your age.  \\n- You are now 70\\u202fyears old.  \\n- Find your sisterâ€™s current age.\\n\\n---\\n\\n## 1.  Ageâ€‘difference method  \\n\\n1. **Find the age gap**  \\n   - At the time you were 6, sister = Â½\\u202fÃ—\\u202f6 = 3.  \\n   - Gap = 6\\u202fâ€“\\u202f3 = **3 years**.\\n\\n2. **Apply the gap to the present**  \\n   - You are 70 now.  \\n   - Sister = 70\\u202fâ€“\\u202f3 = **67**.\\n\\n---\\n\\n## 2.  Ratioâ€‘backâ€‘calculation method  \\n\\n1. **Set up the ratio**  \\n   - When you were 6, sister = Â½\\u202fÃ—\\u202f6 = 3.  \\n   - Ratio of sisterâ€™s age to yours at that time = 3\\u202f:\\u202f6 = Â½.\\n\\n2. **Assume the ratio stays constant**  \\n   - Let current ages be \\\\(S\\\\) (sister) and \\\\(Y = 70\\\\) (you).  \\n   - If the ratio stayed Â½, then \\\\(S = \\\\frac{1}{2}Y = \\\\frac{1}{2}\\\\times70 = 35\\\\).  \\n   - **But** this would ignore the fact that the ratio was only true at that specific past moment, not necessarily now.  \\n   - Instead, use the *difference* derived from the ratio:  \\n     - From 3\\u202f:\\u202f6, the difference is 3 years.  \\n     - Apply that difference: \\\\(S = 70 - 3 = 67\\\\).\\n\\n3. **Result**  \\n   - Sisterâ€™s age = **67**.\\n\\n---\\n\\n## 3.  Timeline (backâ€‘toâ€‘future) method  \\n\\n1. **Create a timeline**  \\n   - Let \\\\(t_0\\\\) be the moment you were 6.  \\n   - At \\\\(t_0\\\\): you = 6, sister = 3.  \\n   - The time elapsed from \\\\(t_0\\\\) to now is \\\\(70 - 6 = 64\\\\) years.\\n\\n2. **Add the elapsed time to both ages**  \\n   - Sisterâ€™s age now = 3 + 64 = **67**.\\n\\n---\\n\\n## Consistency check  \\n\\nAll three independent approaches yield the same result:\\n\\n| Method | Sisterâ€™s age |\\n|--------|--------------|\\n| Ageâ€‘difference | 67 |\\n| Ratioâ€‘backâ€‘calculation | 67 |\\n| Timeline | 67 |\\n\\n**Most consistent result:** **67 years old.**' additional_kwargs={'reasoning_content': 'We need to solve: When I was 6, sister was half my age. So at that time, sister age = 3. So difference in age between them is 3 years. Now I am 70, sister age = 70 - 3 = 67. So answer 67. Provide three independent calculations: maybe using difference, using ratio, using timeline. Provide explanation. Then determine most consistent result: all same 67. Provide final.'} response_metadata={'token_usage': {'completion_tokens': 658, 'prompt_tokens': 112, 'total_tokens': 770, 'completion_time': 0.688389296, 'completion_tokens_details': {'reasoning_tokens': 95}, 'prompt_time': 0.005534103, 'prompt_tokens_details': None, 'queue_time': 0.044972608, 'total_time': 0.693923399}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_5c8ca06ea1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c946f-95b9-74c2-bffa-b052c0054f53-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 112, 'output_tokens': 658, 'total_tokens': 770, 'output_token_details': {'reasoning': 95}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
    "\n",
    "            Provide three independent calculations and explanations, then determine the most consistent result.\n",
    "\n",
    "\"\"\"\n",
    "response = llm.invoke(prompt)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccc4c8",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "Prompt template is a resusable prompt with variables. Instead of writing the same prompt agian we can you create a template and fill the values dynamically. \n",
    "- This is similar to f strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27282c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['adjective', 'content'] input_types={} partial_variables={} template='Tell me a {adjective} joke about {content}'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Tell me a {adjective} joke about {content}\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7060fe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(adjective=\"funny\",content=\"chickens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75a1d5",
   "metadata": {},
   "source": [
    "RunnableLambda lets you insert your own Python function into a LangChain pipeline. We can use it for preprocessing input, modify output, add custom logic, call apis, format data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c256612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define a function to ensure proper formatting\n",
    "def format_prompt(variables):\n",
    "    return prompt.format(**variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0876dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\",\n",
    "               temperature=0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7230e2",
   "metadata": {},
   "source": [
    "### LCEL chain operation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00a8fd",
   "metadata": {},
   "source": [
    "StrOutputParser: Extracts the text from llm response. Note we dont need to extract the content part like we did previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98a3df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the chicken join a band?  \n",
      "\n",
      "Because it had the drumsticks! ğŸ”ğŸ¥\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "joke_chain = (RunnableLambda(format_prompt)\n",
    "              | llm\n",
    "              | StrOutputParser())\n",
    "\n",
    "response = joke_chain.invoke({\"adjective\":\"funny\",\n",
    "                              \"content\":\"chickens\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca003992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the fish feel so lonely at the aquarium?  \n",
      "Because every time it tried to make a splash, it just got a little *tuna* of sadness.\n"
     ]
    }
   ],
   "source": [
    "response = joke_chain.invoke({\"adjective\":\"sad\",\"content\":\"fish\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b108105",
   "metadata": {},
   "source": [
    "### Text summarization with lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d5af408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21stâ€‘century tech breakthroughsâ€”AI, machine learning, and IoTâ€”have reshaped healthcare, education, and transportation, speeding diagnostics, easing traffic, expanding online learning, and fostering a more productive, interconnected society.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "content = \"\"\"\n",
    "    The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation. \n",
    "    Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems. \n",
    "    For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion. \n",
    "    Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers. \n",
    "    These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Summarize the {content} in one sentence\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "summarize_chain = (RunnableLambda(format_prompt)\n",
    "                   | llm\n",
    "                   | StrOutputParser())\n",
    "\n",
    "summary = summarize_chain.invoke({\"content\":content})\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3b268",
   "metadata": {},
   "source": [
    "### Question Answering LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "501a14e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Mercury, Venus, Earth, and Mars.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "content = \"\"\"\n",
    "    The solar system consists of the Sun, eight planets, their moons, dwarf planets, and smaller objects like asteroids and comets. \n",
    "    The inner planetsâ€”Mercury, Venus, Earth, and Marsâ€”are rocky and solid. \n",
    "    The outer planetsâ€”Jupiter, Saturn, Uranus, and Neptuneâ€”are much larger and gaseous.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Which planets in the solar system are rocky and solid?\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Answer the {question} based on the {content}.\n",
    "    Respond \"Unsure about answer\" if not sure about how to answer.\n",
    "\n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = (RunnableLambda(format_prompt)\n",
    "            | llm\n",
    "            | StrOutputParser())\n",
    "\n",
    "response = qa_chain.invoke({\"question\":question,\"content\":content})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623a4f4",
   "metadata": {},
   "source": [
    "### Text classification using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef24969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "text = \"\"\"\n",
    "    The concert last night was an exhilarating experience with outstanding performances by all artists.\n",
    "\"\"\"\n",
    "\n",
    "categories = \"Entertainment, Food and Dining, Technology, Literature, Music.\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Classify the {text} into one of the {categories}.\n",
    "    \n",
    "    Category:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "clf_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "category = clf_chain.invoke({\"text\":text,\"categories\":categories})\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af87ac67",
   "metadata": {},
   "source": [
    "### Code generation with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db2fd642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**SQL Query**\n",
      "\n",
      "```sql\n",
      "SELECT DISTINCT c.name, c.email\n",
      "FROM customers      AS c\n",
      "JOIN purchases      AS p\n",
      "     ON p.customer_id = c.id\n",
      "WHERE p.purchase_date >= NOW() - INTERVAL '30 days';\n",
      "```\n",
      "\n",
      "*If youâ€™re using MySQL, replace the date comparison with:*\n",
      "\n",
      "```sql\n",
      "WHERE p.purchase_date >= DATE_SUB(NOW(), INTERVAL 30 DAY);\n",
      "```\n",
      "\n",
      "This query returns the unique names and email addresses of all customers who have made at least one purchase in the past 30 days.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "description = \"\"\"\n",
    "    Retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days. \n",
    "    The table 'purchases' contains a column 'purchase_date'\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Generate a SQL query based on the {description}\n",
    "\n",
    "    SQL Query:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "sql_chain = (RunnableLambda(format_prompt)\n",
    "             | llm\n",
    "             | StrOutputParser())\n",
    "\n",
    "sql_query = sql_chain.invoke({\"description\":description})\n",
    "\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad83a0",
   "metadata": {},
   "source": [
    "### Role Play"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61a00a",
   "metadata": {},
   "source": [
    "You can also configure the LLM to assume specific roles as defined by us, enabling it to follow predetermined rules and behave like a task-oriented chatbot.\n",
    "\n",
    "This approach separates the role definition from the prompt structure, allowing for easy role-switching without rewriting the entire prompt. The key components are:\n",
    "\n",
    "- `role`: Specifies the character, expertise, or persona the LLM should embody\n",
    "- `tone`: Defines the communication style and emotional quality of responses\n",
    "- `question`: Contains the user's query that needs addressing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e84bcd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: **The Great Cosmic Tapestry: A Dungeon Masterâ€™s Guide to the Solid Worlds**\n",
      "\n",
      "*You find yourself aboard the starâ€‘ship *Eclipse*, a sleek vessel that has slipped through the veil of the Astral Sea and entered the familiar orbit of the Sun. The crew is hushed, the engines humming, as the captain points to the glowing map projected on the wall.*\n",
      "\n",
      "> **Captain:** â€œListen up, crew. Weâ€™re about to chart the four solid worlds that make up the inner sanctum of our solar system. These are the only planets that boast a rocky crust, a core of metal, and a surface that can support a civilizationâ€”if youâ€™re lucky enough to find one.â€\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Mercury â€“ The Swift Sentinel**\n",
      "\n",
      "- **Distance from the Sun:** 0.39 AU  \n",
      "- **Diameter:** 4,880â€¯km  \n",
      "- **Surface:** A barren, craterâ€‘scarred wasteland of silicate rock, with no atmosphere to speak of.  \n",
      "- **Flavor:** â€œMercury is a lone wanderer, a swift sentinel that races the Sun. Its surface is a mosaic of ancient impact scars, and the temperature swings from blistering heat to boneâ€‘chilling cold. A hardy explorer might find pockets of regolith that whisper of ancient volcanic activity.â€\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Venus â€“ The Veiled Inferno**\n",
      "\n",
      "- **Distance from the Sun:** 0.72 AU  \n",
      "- **Diameter:** 12,104â€¯km  \n",
      "- **Surface:** Thick, toxic clouds of sulfuric acid, but beneath them lies a rocky mantle and a molten core.  \n",
      "- **Flavor:** â€œVenus is the goddess of fire, cloaked in a shroud of poisonous clouds. Its surface is a blistering furnace, with temperatures hot enough to melt lead. Yet beneath the haze, the world is a solid rock, a potential battlefield for those daring enough to brave its deadly winds.â€\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Earth â€“ The Verdant Jewel**\n",
      "\n",
      "- **Distance from the Sun:** 1.00 AU  \n",
      "- **Diameter:** 12,742â€¯km  \n",
      "- **Surface:** A dynamic, waterâ€‘rich planet with continents, oceans, and a breathable atmosphere.  \n",
      "- **Flavor:** â€œEarth is the jewel of the solar systemâ€”teeming with life, lush forests, and vast oceans. Its crust is a mosaic of tectonic plates, and its magnetic field shields it from cosmic storms. A realm where adventurers can find both wonder and danger in equal measure.â€\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **Mars â€“ The Red Frontier**\n",
      "\n",
      "- **Distance from the Sun:** 1.52 AU  \n",
      "- **Diameter:** 6,779â€¯km  \n",
      "- **Surface:** A dusty, ironâ€‘oxideâ€‘rich landscape with towering volcanoes and deep canyons.  \n",
      "- **Flavor:** â€œMars is the red frontier, a world of ancient rivers and colossal volcanoes. Its thin atmosphere and cold climate make it a harsh but intriguing destination. Rumors speak of buried ice caps and the possibility of ancient life hidden beneath the dust.â€\n",
      "\n",
      "---\n",
      "\n",
      "### The â€œOtherâ€ Solid Bodies (Optional)\n",
      "\n",
      "- **Ceres, Vesta, Pallas, Hygiea** â€“ Dwarf planets and asteroids in the asteroid belt, composed largely of rock and ice.  \n",
      "- **Pluto, Eris, Haumea, Makemake** â€“ Dwarf planets beyond Neptune, largely icy but with rocky cores.  \n",
      "- **Note:** These bodies are solid, but they are not classified as the â€œrocky planetsâ€ of the inner solar system.\n",
      "\n",
      "---\n",
      "\n",
      "### How to Use This Knowledge in Your Campaign\n",
      "\n",
      "1. **Traveling Through the Inner Sanctum**  \n",
      "   *Your partyâ€™s starship can dock at any of these worlds. Each offers unique quests: salvage operations on Mercuryâ€™s regolith, diplomatic negotiations with a Venusian court, ecological research on Earth, or a treasure hunt in Marsâ€™ ancient valleys.*\n",
      "\n",
      "2. **Planetary Quests**  \n",
      "   *Mercuryâ€™s ancient ruins, Venusâ€™s hidden temples beneath the acid clouds, Earthâ€™s bustling megacities, or Marsâ€™ forgotten mining coloniesâ€”each world can host a full campaign arc.*\n",
      "\n",
      "3. **Environmental Hazards**  \n",
      "   *Remember the temperature extremes, atmospheric composition, and geological activity. A spell that manipulates fire may be deadly on Mercury, while a waterâ€‘based spell could be a boon on Earth.*\n",
      "\n",
      "4. **Cultural Lore**  \n",
      "   *Each planet can be home to distinct cultures: the hardy miners of Mercury, the cloudâ€‘dwelling scholars of Venus, the diverse ecosystems of Earth, and the pioneering settlers of Mars.*\n",
      "\n",
      "---\n",
      "\n",
      "**Captain:** â€œAlright, crew. Weâ€™ve identified the solid worlds. Now letâ€™s decide where weâ€™ll land first. The choice is yoursâ€”each planet holds its own peril and promise.â€\n",
      "\n",
      "*The crew nods, their eyes alight with the thrill of the unknown. The *Eclipse* turns its course toward the next world, and the adventure continuesâ€¦*\n",
      "answer: **The Four Stones of the Sun**\n",
      "\n",
      "*Listen, traveler, and let me paint you a picture of the worlds that cling to the Sun like stubborn, unyielding stones. These are the only planets that bear the weight of solid rock, the kind of world that would feel the thud of a warhammer against its crust.*\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Mercury â€“ The Swift, Scorched Sentinel**\n",
      "\n",
      "- **Surface**: A jagged, craterâ€‘scarred landscape, its plains a mosaic of ancient lava flows and fresh impact craters. The planetâ€™s thin exosphere whispers of a onceâ€‘thicker atmosphere that has long since fled.\n",
      "- **Composition**: Ironâ€‘rich core, a silicate mantle, and a thin crust. Its surface is a rocky, metallic alloy, with a high density that makes it feel like a stone that could crush a dwarf.\n",
      "- **Why It Matters**: In a campaign, Mercury could be a moonâ€‘laden mining outpost, a place where the heat of the Sun burns the ore and the shadows hide forgotten tombs.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Venus â€“ The Veiled Inferno**\n",
      "\n",
      "- **Surface**: Thick, sulfuric clouds veil a world of volcanic plains and towering mountain ranges. The ground is a basaltic crust, riddled with fissures that hiss with molten fury.\n",
      "- **Composition**: A silicate mantle and crust, with a dense, ironâ€‘rich core. The planetâ€™s gravity is strong enough to hold a crushing atmosphere of carbon dioxide and sulfuric acid.\n",
      "- **Why It Matters**: Venus is a realm of eternal twilight, a place where the heat can melt steel and the winds can carry whispers of ancient civilizations buried beneath ash.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Earth â€“ The Living Blue Marble**\n",
      "\n",
      "- **Surface**: A dynamic tapestry of continents, oceans, deserts, and ice caps. The crust is a mosaic of tectonic plates that shift, collide, and create mountains, earthquakes, and volcanic eruptions.\n",
      "- **Composition**: A silicate crust and mantle, with a liquid ironâ€‘nickel outer core and a solid inner core. The planetâ€™s magnetic field shields it from cosmic radiation.\n",
      "- **Why It Matters**: Earth is the cradle of life, a living world where every stone, tree, and creature has a story. In a D&D setting, it could be the â€œhome worldâ€ of the party, a place of bustling cities, ancient ruins, and untamed wilderness.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **Mars â€“ The Red Frontier**\n",
      "\n",
      "- **Surface**: A dusty, ironâ€‘oxideâ€‘rich terrain with towering volcanoes (Olympus Mons), colossal canyons (Valles Marineris), and polar ice caps that glitter in the thin atmosphere.\n",
      "- **Composition**: A silicate crust and mantle, with a smaller iron core than Earthâ€™s. Its thin atmosphere is mostly carbon dioxide, with traces of water vapor.\n",
      "- **Why It Matters**: Mars is a frontier of exploration, a place where brave adventurers might uncover relics of a lost civilization, survive dust storms, and perhaps even terraform a new home.\n",
      "\n",
      "---\n",
      "\n",
      "## The Gas Giants â€“ Not for the Solidâ€‘Hearted\n",
      "\n",
      "- **Jupiter, Saturn, Uranus, Neptune**: These behemoths are composed of hydrogen, helium, and other volatile gases. While they may have rocky cores deep beneath their swirling atmospheres, they are not â€œrocky planetsâ€ in the sense of a solid, walkable surface. Think of them as massive, floating citadels rather than stone kingdoms.\n",
      "\n",
      "---\n",
      "\n",
      "### Quick Reference\n",
      "\n",
      "| Planet | Rocky? | Key Features |\n",
      "|--------|--------|--------------|\n",
      "| Mercury | Yes | Iron core, basaltic crust, extreme temperatures |\n",
      "| Venus | Yes | Volcanic plains, dense atmosphere |\n",
      "| Earth | Yes | Dynamic crust, life, magnetic field |\n",
      "| Mars | Yes | Ironâ€‘oxide terrain, polar ice, potential for terraforming |\n",
      "| Jupiter | No | Gas giant, no solid surface |\n",
      "| Saturn | No | Gas giant, rings |\n",
      "| Uranus | No | Ice giant, mostly hydrogen/helium |\n",
      "| Neptune | No | Ice giant, mostly hydrogen/helium |\n",
      "\n",
      "---\n",
      "\n",
      "**In the grand tapestry of the cosmos, only Mercury, Venus, Earth, and Mars hold the hard, unyielding heart of stone.**  \n",
      "They are the worlds that can be walked upon, mined, and exploredâ€”perfect for a D&D campaign where the party might traverse deserts, scale volcanoes, or uncover buried temples beneath the sands of time.  \n",
      "\n",
      "May your adventures be as enduring as the rocky worlds themselves!\n",
      "Answer: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "role = \"\"\"\n",
    "    Dungeon & Dragons game masters\n",
    "\"\"\"\n",
    "\n",
    "tone = \"engaging and immersive\"\n",
    "\n",
    "template = \"\"\"\n",
    "    You are an expert {role}. I have this question {question}. I would like our conversation to be {tone}.\n",
    "\n",
    "    Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "roleplay_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "while True:\n",
    "    query = input(\"Question: \")\n",
    "\n",
    "    if query.lower() in [\"quit\",\"exit\",\"bye\"]:\n",
    "        print(\"Answer: Goodbye!\")\n",
    "        break \n",
    "    \n",
    "    response = roleplay_chain.invoke({\"role\":role,\n",
    "                                      \"question\":question,\n",
    "                                      \"tone\":tone})\n",
    "\n",
    "    print(\"answer:\",response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66766115",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "**Create an LCEL Chain with Custom Formatting**\n",
    "\n",
    "In this exercise, you'll create your own LCEL chain that uses prompt templates to build a custom application.\n",
    "\n",
    "**Task:** Create a product review analyzer that can:\n",
    "1. Identify the sentiment (positive, negative, or neutral).\n",
    "2. Extract mentioned product features.\n",
    "3. Provide a one-sentence summary of the review.\n",
    "\n",
    "**Steps:**\n",
    "1. Create a prompt template with placeholders for the review text.\n",
    "2. Build an LCEL chain that formats your prompt properly.\n",
    "3. Process the sample reviews and display the results.\n",
    "4. Try modifying the chain to change the output format.\n",
    "\n",
    "**Sample input:**\n",
    "```python\n",
    "reviews = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32def5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Review 1 â€“ Smartphone**\n",
      "\n",
      "- Sentiment: positive  \n",
      "- Key Features Mentioned: camera quality, battery life, heating during gaming  \n",
      "- Summary: A smartphone praised for its exceptional camera and allâ€‘day battery, but it tends to heat up slightly while gaming.  \n",
      "\n",
      "---\n",
      "\n",
      "**Review 2 â€“ Laptop**\n",
      "\n",
      "- Sentiment: negative  \n",
      "- Key Features Mentioned: performance (slow), stability (frequent crashes), keyboard durability, customer service  \n",
      "- Summary: A laptop criticized for being slow, prone to crashes, having a faulty keyboard after two months, and receiving unhelpful customer support.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "text = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]\n",
    "\n",
    "categories = \"Positive, Negative, Neutral\"\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Analyze the following product review:\n",
    "\"{review}\"\n",
    "\n",
    "Provide your analysis in the following format:\n",
    "- Sentiment: (positive, negative, or neutral)\n",
    "- Key Features Mentioned: (list the product features mentioned)\n",
    "- Summary: (one-sentence summary)\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "clf_chain = (RunnableLambda(format_prompt)\n",
    "             | llm\n",
    "             | StrOutputParser())\n",
    "\n",
    "cat_preds = clf_chain.invoke({\"review\":text})\n",
    "print(cat_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
